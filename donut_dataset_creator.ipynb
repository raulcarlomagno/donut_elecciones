{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import isfile\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_directory_to_zip(root_path, zip_name):\n",
    "    import zipfile\n",
    "    import os\n",
    "\n",
    "    with zipfile.ZipFile(zip_name, 'w', compression=zipfile.ZIP_DEFLATED, compresslevel=9) as z:\n",
    "        for root, dirs, files in os.walk(root_path):\n",
    "            for file in files:\n",
    "                z.write(os.path.join(root, file))\n",
    "            for directory in dirs:\n",
    "                z.write(os.path.join(root, directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_resultados = pd.read_csv('data/resultados_mesas.csv')\n",
    "df_resultados = pd.read_csv('data/resultados_mesas_full.csv')\n",
    "\n",
    "# df_resultados = df_resultados.astype(dict.fromkeys(df_resultados.select_dtypes('int64').columns, 'int'))\n",
    "# df_resultados.set_index('mesa_id', inplace=True)\n",
    "print(len(df_resultados))\n",
    "\n",
    "df_resultados = df_resultados[~(\n",
    "    (df_resultados[\"massa\"] == 0) &\n",
    "    (df_resultados[\"bullrich\"] == 0) &\n",
    "    (df_resultados[\"milei\"] == 0) &\n",
    "    (df_resultados[\"bregman\"] == 0) &\n",
    "    (df_resultados[\"schiaretti\"] == 0)\n",
    ")]\n",
    "print(len(df_resultados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_resultados.groupby(['distrito'])['distrito'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mesas = pd.read_csv('data/mesas_por_localidad.csv', encoding='latin1')\n",
    "# print(len(df_mesas.index))\n",
    "\n",
    "# distrito_nombre = \"Ciudad Autónoma de Buenos Aires\"\n",
    "# distrito_nombre = \"Jujuy\"\n",
    "# distrito_nombre = \"Río Negro\"\n",
    "# df_resultados = df_resultados[df_resultados['distrito'] == distrito_nombre]\n",
    "# len(df_resultados)\n",
    "\n",
    "df_resultados = df_resultados[df_resultados['distrito'].isin([\"Ciudad Autónoma de Buenos Aires\", \"Jujuy\", \"Río Negro\"])]\n",
    "print(len(df_resultados.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left,right,top,bottom\n",
    "cropping_values_mapping = {\n",
    "    \"Ciudad Autónoma de Buenos Aires\": (.09, .4, .27, .48),\n",
    "    \"Jujuy\": (.09, .57, .25, .5),\n",
    "    \"Río Negro\": (.09, .59, .25, .47),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import json\n",
    "from PIL import Image as PilImage\n",
    "\n",
    "shutil.rmtree('data/donut_dataset', ignore_errors=True)\n",
    "\n",
    "types_dataset = ('train', 'validation', 'test')\n",
    "types_dataset_paths = {}\n",
    "\n",
    "for type_dataset in types_dataset:\n",
    "    dataset_path = f'data/donut_dataset/{type_dataset}/'\n",
    "    types_dataset_paths[type_dataset] = dataset_path\n",
    "    Path(dataset_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_sample_per_distrito = 300\n",
    "distritos_disponibles = df_resultados['distrito'].unique().tolist()\n",
    "df_resultados_sampled = []\n",
    "\n",
    "for distrito in distritos_disponibles:\n",
    "    df_resultados_sampled.append(df_resultados[df_resultados['distrito'] == distrito].sample(n=rows_to_sample_per_distrito, random_state=42))\n",
    "\n",
    "df_resultados_sampled = pd.concat(df_resultados_sampled)\n",
    "df_resultados_sampled = df_resultados_sampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_resultados_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = df_resultados_sampled.shape[0]\n",
    "# limit = 100 #1200\n",
    "output_image_size = 640\n",
    "\n",
    "telegrama_or_resultado_not_found = []\n",
    "\n",
    "dataset_items = defaultdict(list)\n",
    "\n",
    "for index, row in tqdm(df_resultados_sampled[:limit].iterrows(), total=limit):\n",
    "    mesa_id = row['mesa_id']\n",
    "    distrito = row['distrito']\n",
    "    telegrama_image_path = f\"data/telegramas/{distrito}/{mesa_id}.tiff\"\n",
    "\n",
    "    if isfile(telegrama_image_path):\n",
    "        current_mesa_last_value = int(mesa_id[-2])\n",
    "\n",
    "        if current_mesa_last_value == 0:\n",
    "            item_dataset_type = 2 #test\n",
    "        elif current_mesa_last_value == 9:\n",
    "            item_dataset_type = 1 #validation\n",
    "        else:\n",
    "            item_dataset_type = 0 #train\n",
    "        item_dataset_type = types_dataset[item_dataset_type]\n",
    "\n",
    "        image_save_filename = mesa_id + '.tiff'\n",
    "\n",
    "        item = {\n",
    "            \"file_name\": mesa_id + '.jpg',\n",
    "            \"ground_truth\": {\n",
    "                \"gt_parse\": dict()\n",
    "            }\n",
    "        }\n",
    "\n",
    "        for candidato_nombre in (\"massa\", \"bullrich\", \"milei\", \"bregman\", \"schiaretti\"):\n",
    "            item[\"ground_truth\"][\"gt_parse\"][candidato_nombre] = str(row.get(candidato_nombre))\n",
    "\n",
    "        dataset_items[item_dataset_type].append(item)\n",
    "        save_image_path = f\"{types_dataset_paths[item_dataset_type]}{image_save_filename}\"\n",
    "\n",
    "        telegrama_tiff = PilImage.open(telegrama_image_path)\n",
    "\n",
    "        telegrama_tiff_width, telegrama_tiff_height = telegrama_tiff.size\n",
    "\n",
    "        cropping_values_distrito = cropping_values_mapping[distrito]\n",
    "\n",
    "        crop_left = int(telegrama_tiff_width * cropping_values_distrito[0])\n",
    "        crop_right = int(telegrama_tiff_width * cropping_values_distrito[1])\n",
    "        crop_top = int(telegrama_tiff_height * cropping_values_distrito[2])\n",
    "        crop_bottom = int(telegrama_tiff_height * cropping_values_distrito[3])\n",
    "\n",
    "        cropped_telegrama = telegrama_tiff.crop((crop_left, crop_top, crop_right, crop_bottom))\n",
    "\n",
    "        cropped_telegrama_original_size = cropped_telegrama.size\n",
    "        ratio = float(output_image_size)/max(cropped_telegrama_original_size)\n",
    "        new_size = tuple([int(x*ratio) for x in cropped_telegrama_original_size])\n",
    "        cropped_telegrama = cropped_telegrama.resize(new_size)\n",
    "\n",
    "        canvas = PilImage.new('1', (output_image_size, output_image_size) , (0))\n",
    "        canvas.paste(cropped_telegrama, ((output_image_size-new_size[0])//2, (output_image_size-new_size[1])//2))\n",
    "\n",
    "        canvas.save(save_image_path, optimize=True)\n",
    "\n",
    "    else:\n",
    "        telegrama_or_resultado_not_found.append(mesa_id)\n",
    "\n",
    "for dataset_type in dataset_items.keys():\n",
    "    print('length', dataset_type, len(dataset_items[dataset_type]), len(dataset_items[dataset_type])/limit)\n",
    "\n",
    "for dataset_type in dataset_items.keys():\n",
    "    with open(types_dataset_paths[dataset_type] + 'metadata.jsonl', 'w') as fp:    \n",
    "        for item in dataset_items[dataset_type]:\n",
    "            line = {\"file_name\": item[\"file_name\"], \"ground_truth\": json.dumps(item[\"ground_truth\"])}\n",
    "            fp.write(json.dumps(line) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_directory_to_zip('data/donut_dataset/', 'data/donut_dataset_elecciones.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
